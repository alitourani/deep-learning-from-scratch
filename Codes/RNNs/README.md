# Recurrent Neural Networks (RNNs)

In contrast with Feed-Forward NNs in which the information is only passed in one direction, RNNs can easily handle sequential data processing. These architectures of Artificial Neural Networks (ANNs) can remember previous inputs, share the features across the network, and use historical information.

![RNNs](https://github.com/alitourani/deep-learning-from-scratch/blob/main/_content/AliTourani-DeepLearningFromScratch-RecurrentNeuralNetwork-RNN.png "RNNs")

## ðŸ“š Codes

| # | File | Description |
| --- | ------------ | ------------ |
| 0 | [RNN layers](https://github.com/alitourani/deep-learning-from-scratch/blob/main/Codes/RNNs/0_KerasRecurrentLayers.ipynb "RNN layers") | Introduction to Keras RNN layers |

## ðŸ§© Use cases (to be added)
- Image captioning
- Sentiment classification
- Machine translation
- Named entity recognition
- Speech Recognition
- Stock prediction
- Chatbot
- Word prediction
- Music generation
- Trajectory prediction
