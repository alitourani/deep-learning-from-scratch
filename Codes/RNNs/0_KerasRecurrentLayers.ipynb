{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0-KerasRecurrentLayers.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNtmWqq2GH+YL85gxFBD+3K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alitourani/deep-learning-from-scratch/blob/main/Codes/RNNs/0_KerasRecurrentLayers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rME0XeLTEP6o"
      },
      "source": [
        "**I. A Simple Recurrent Neural Network (RNN)**\n",
        "- [Simple RNN in Keras](https://keras.io/api/layers/recurrent_layers/simple_rnn)\n",
        "- [Working with RNNs](https://keras.io/guides/working_with_rnns/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyp-KWZ1UNOG",
        "outputId": "9f7d43f7-25ed-4180-abb5-189e802b42d0"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras.layers import SimpleRNN\n",
        "\n",
        "inputs = np.random.random([32, 10, 8]).astype(np.float32)\n",
        "simpleRecurrentNet = SimpleRNN(4) # A fully-connected RNN where the output from previous timestep is to be fed to next timestep\n",
        "\n",
        "output = simpleRecurrentNet(inputs) # Shape: [32, 4]\n",
        "\n",
        "simpleRecurrentNet = SimpleRNN(\n",
        "    4,\n",
        "    return_sequences=True,\n",
        "    return_state=True)\n",
        "\n",
        "wholeSequenceOutput, finalState = simpleRecurrentNet(inputs)\n",
        "print(wholeSequenceOutput.shape, finalState.shape) # (32, 10, 4) (32, 4)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 10, 4) (32, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lnbTe1pXJli"
      },
      "source": [
        "**II. A Long Short-Term Memory Layer**\n",
        "- [LSTM layer in Keras](https://keras.io/api/layers/recurrent_layers/lstm/)\n",
        "- [Working with RNNs](https://keras.io/guides/working_with_rnns/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AO1biMguX_Qc",
        "outputId": "67ef233e-ec10-4017-ad05-0063e6d50520"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras.layers import LSTM\n",
        "\n",
        "inputs = np.random.random([32, 10, 8]).astype(np.float32)\n",
        "lstmLayer = LSTM(4)\n",
        "\n",
        "output = lstmLayer(inputs) # Shape: [32, 4]\n",
        "\n",
        "lstmLayer = LSTM(\n",
        "    4,\n",
        "    return_sequences=True,\n",
        "    return_state=True)\n",
        "\n",
        "wholeSequenceOutput, finalMemoryState, finalCarryState = lstmLayer(inputs)\n",
        "print(wholeSequenceOutput.shape, finalMemoryState.shape, finalCarryState.shape) # (32, 10, 4) (32, 4) (32, 4)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 10, 4) (32, 4) (32, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ggSzIv5YmQL"
      },
      "source": [
        "**III. A Gated Recurrent Unit (GRU) Layer**\n",
        "- [GRU layer in Keras](https://keras.io/api/layers/recurrent_layers/gru/)\n",
        "- [Working with RNNs](https://keras.io/guides/working_with_rnns/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ougbcZPHYlAb",
        "outputId": "8b8643ba-a707-4c22-866c-3f59ea92da86"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras.layers import GRU\n",
        "\n",
        "inputs = np.random.random([32, 10, 8]).astype(np.float32)\n",
        "gruLayer = GRU(4)\n",
        "\n",
        "output = gruLayer(inputs) # Shape: [32, 4]\n",
        "\n",
        "gruLayer = GRU(\n",
        "    4,\n",
        "    return_sequences=True,\n",
        "    return_state=True)\n",
        "\n",
        "wholeSequenceOutput, finalState = gruLayer(inputs)\n",
        "print(wholeSequenceOutput.shape, finalState.shape) # (32, 10, 4) (32, 4)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 10, 4) (32, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_mLf6VsZiBz"
      },
      "source": [
        "**IV. A Bidirectional Layer**\n",
        "- [Bidirectional layer in Keras](https://keras.io/api/layers/recurrent_layers/bidirectional/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6qMSX3hZyOL",
        "outputId": "05b289a3-d279-43bd-c3e0-b36a63f409de"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Bidirectional, Dense, LSTM\n",
        "\n",
        "lstmLayer = LSTM(\n",
        "    10,\n",
        "    return_sequences=True)\n",
        "\n",
        "bidirectional1 = Bidirectional(lstmLayer, input_shape=(5, 10))\n",
        "bidirectional2 = Bidirectional(LSTM(10))\n",
        "\n",
        "sequentialModel = Sequential()\n",
        "sequentialModel.add(bidirectional1)\n",
        "sequentialModel.add(bidirectional2)\n",
        "sequentialModel.add(Dense(5))\n",
        "sequentialModel.add(Activation('softmax'))\n",
        "sequentialModel.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "sequentialModel.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional_12 (Bidirectio (None, 5, 20)             1680      \n",
            "_________________________________________________________________\n",
            "bidirectional_13 (Bidirectio (None, 20)                2480      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 5)                 105       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 4,265\n",
            "Trainable params: 4,265\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}